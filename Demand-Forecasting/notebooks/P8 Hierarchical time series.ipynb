{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasetsforecast\n",
    "# !pip install hierarchicalforecast\n",
    "# !pip install statsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from datasetsforecast.hierarchical import HierarchicalData\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import  BottomUp, TopDown, MiddleOut, MinTrace, ERM\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, Naive\n",
    "from hierarchicalforecast.evaluation import HierarchicalEvaluation\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings\n",
    "class CFG:\n",
    "    data_folder = '../SAP_AI/Demand Forecasting/Datasets/'\n",
    "    img_dim1 = 20\n",
    "    img_dim2 = 10\n",
    "\n",
    "# adjust the parameters for displayed figures    \n",
    "plt.rcParams.update({'figure.figsize': (CFG.img_dim1,CFG.img_dim2)})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rmse(x,y):\n",
    "    return(np.round( np.sqrt(mse(x.values,y.values)) ,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sales_qty</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>7</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date store_id  sales_qty state_id\n",
       "10680 2014-01-01     CA_1          3       CA\n",
       "10681 2014-01-01     CA_2          0       CA\n",
       "10682 2014-01-01     CA_3          7       CA"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sales data calendar_df = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv', parse_dates=['date'])\n",
    "file_path = '/home/user/projects/SAP_AI/Demand Forecasting/Datasets/'\n",
    "calendar_df = pd.read_csv(file_path + 'calendar.csv', parse_dates=['date'])\n",
    "calendar_df = calendar_df.loc[:, ['date', 'wm_yr_wk', 'd']]\n",
    "df = pd.read_csv(file_path + 'sales_train_evaluation.csv')\n",
    "df = df.loc[df.item_id=='FOODS_3_819']\n",
    "df_T = df.melt(id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])\n",
    "df_T.drop(columns=['id'], inplace=True)\n",
    "\n",
    "sales_df = df_T.merge(calendar_df, left_on='variable', right_on='d', how='left')\n",
    "sales_df.rename(columns={'value': 'sales_qty'}, inplace=True)\n",
    "df = sales_df.loc[sales_df.date >= '2014-01-01', ['date', 'store_id', 'sales_qty']]\n",
    "df['state_id'] = df['store_id'].str[:2]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date store_id  sales_qty state_id\n",
      "10680 2022-01-01     CA_1          3       CA\n",
      "10681 2022-01-01     CA_2          0       CA\n",
      "10682 2022-01-01     CA_3          7       CA\n",
      "10683 2022-01-01     CA_4          0       CA\n",
      "10684 2022-01-01     TX_1          0       TX\n",
      "...          ...      ...        ...      ...\n",
      "19405 2024-05-22     TX_2          0       TX\n",
      "19406 2024-05-22     TX_3          1       TX\n",
      "19407 2024-05-22     WI_1          7       WI\n",
      "19408 2024-05-22     WI_2          0       WI\n",
      "19409 2024-05-22     WI_3          1       WI\n",
      "\n",
      "[8730 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure that 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Add five years using DateOffset\n",
    "df['date'] = df['date'] + pd.DateOffset(years=8)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8730, 3) (2619, 3) (873, 3) (12222, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>TX_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>WI_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds unique_id  y\n",
       "0 2022-01-01      CA_1  3\n",
       "1 2022-01-01      CA_2  0\n",
       "2 2022-01-01      CA_3  7\n",
       "3 2022-01-01      CA_4  0\n",
       "4 2022-01-01      TX_1  0\n",
       "5 2022-01-01      TX_2  1\n",
       "6 2022-01-01      TX_3  1\n",
       "7 2022-01-01      WI_1  1\n",
       "8 2022-01-01      WI_2  0\n",
       "9 2022-01-01      WI_3  3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the long format matrix: individual stores\n",
    "df_ind = df.groupby(['date', 'store_id'])[['sales_qty']].sum()\n",
    "df_ind.reset_index(inplace=True)\n",
    "df_ind = df_ind.T.reset_index(drop=True).T\n",
    "df_ind.columns = ['ds', 'unique_id', 'sales']\n",
    "\n",
    "# create the long format matrix: state level\n",
    "df_sta = df.groupby(['date', 'state_id'])[['sales_qty']].sum()\n",
    "df_sta.reset_index(inplace=True)\n",
    "df_sta.columns = ['ds', 'unique_id', 'sales']\n",
    "\n",
    "# create the long format matrix: total level\n",
    "df_tot = df.groupby(['date'])[['sales_qty']].sum()\n",
    "df_tot.reset_index(inplace=True)\n",
    "df_tot['unique_id'] = 'Total'\n",
    "df_tot.columns = ['ds', 'sales', 'unique_id' ]\n",
    "\n",
    "\n",
    "# combine all three\n",
    "dfx = pd.concat([df_ind, df_sta, df_tot], axis = 0)\n",
    "print(df_ind.shape, df_sta.shape, df_tot.shape, dfx.shape)\n",
    "\n",
    "# format\n",
    "xset = set(dfx.unique_id)\n",
    "dfx.columns = ['ds','unique_id', 'y']\n",
    "dfx['ds'] = pd.to_datetime(dfx['ds'])\n",
    "dfx.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21447/4040101078.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  S.loc['CA'][['CA_1','CA_2','CA_3', 'CA_4']] = 1\n",
      "/tmp/ipykernel_21447/4040101078.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  S.loc['TX'][['TX_1','TX_2','TX_3']] = 1\n",
      "/tmp/ipykernel_21447/4040101078.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  S.loc['WI'][['WI_1','WI_2','WI_3']] = 1\n",
      "/tmp/ipykernel_21447/4040101078.py:16: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  S.loc[x][x]= 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>TX_1</th>\n",
       "      <th>TX_2</th>\n",
       "      <th>TX_3</th>\n",
       "      <th>WI_1</th>\n",
       "      <th>WI_2</th>\n",
       "      <th>WI_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CA_1  CA_2  CA_3  CA_4  TX_1  TX_2  TX_3  WI_1  WI_2  WI_3\n",
       "Total     1     1     1     1     1     1     1     1     1     1\n",
       "CA        1     1     1     1     0     0     0     0     0     0\n",
       "CA_1      1     0     0     0     0     0     0     0     0     0\n",
       "CA_2      0     1     0     0     0     0     0     0     0     0\n",
       "CA_3      0     0     1     0     0     0     0     0     0     0\n",
       "CA_4      0     0     0     1     0     0     0     0     0     0\n",
       "TX        0     0     0     0     1     1     1     0     0     0\n",
       "TX_1      0     0     0     0     1     0     0     0     0     0\n",
       "TX_2      0     0     0     0     0     1     0     0     0     0\n",
       "TX_3      0     0     0     0     0     0     1     0     0     0\n",
       "WI        0     0     0     0     0     0     0     1     1     1\n",
       "WI_1      0     0     0     0     0     0     0     1     0     0\n",
       "WI_2      0     0     0     0     0     0     0     0     1     0\n",
       "WI_3      0     0     0     0     0     0     0     0     0     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.zeros((len(xset), len([f for f in xset if '_' in f])))\n",
    "\n",
    "\n",
    "# rows / columns\n",
    "list1 = ['Total', 'CA','CA_1','CA_2','CA_3','CA_4','TX','TX_1','TX_2','TX_3','WI','WI_1','WI_2','WI_3']\n",
    "list2 = ['CA_1','CA_2','CA_3','CA_4','TX_1','TX_2','TX_3','WI_1','WI_2','WI_3']\n",
    "S = pd.DataFrame(S); S.index = list1; S.columns = list2\n",
    "\n",
    "\n",
    "# encode the hierarchical structure\n",
    "S.loc['Total'] = 1\n",
    "S.loc['CA'][['CA_1','CA_2','CA_3', 'CA_4']] = 1\n",
    "S.loc['TX'][['TX_1','TX_2','TX_3']] = 1\n",
    "S.loc['WI'][['WI_1','WI_2','WI_3']] = 1\n",
    "for x in S.columns:\n",
    "    S.loc[x][x]= 1\n",
    "S = S.astype(int)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': array(['Total'], dtype=object),\n",
       " 'Country/State': array(['CA', 'TX', 'WI'], dtype=object),\n",
       " 'Country/State/Store': array(['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1',\n",
       "        'WI_2', 'WI_3'], dtype=object)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {}\n",
    "tags['Country'] = np.array(['Total'], dtype=object)\n",
    "tags['Country/State'] = np.array(['CA', 'TX', 'WI'], dtype=object)\n",
    "tags['Country/State/Store'] = np.array(['CA_1', 'CA_2', 'CA_3', 'CA_4',  \n",
    "                                        'TX_1', 'TX_2', 'TX_3',\n",
    "                                        'WI_1', 'WI_2', 'WI_3'], dtype=object)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 7 \n",
    "\n",
    "x_test = dfx.groupby('unique_id').tail(horizon)\n",
    "x_train = dfx.drop(x_test.index)\n",
    "x_test = x_test.set_index('unique_id')\n",
    "x_train = x_train.set_index('unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds    datetime64[ns]\n",
      "y             object\n",
      "dtype: object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check data types of the DataFrame\n",
    "print(x_train.dtypes)\n",
    "\n",
    "# Ensure the target column 'y' is numeric\n",
    "x_train['y'] = pd.to_numeric(x_train['y'], errors='coerce')\n",
    "\n",
    "# Check if there are any NaN values introduced by coercion\n",
    "print(x_train['y'].isna().sum())\n",
    "\n",
    "# Drop or handle NaN values if any were introduced\n",
    "x_train = x_train.dropna(subset=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projects/SAP_AI/env/lib/python3.11/site-packages/statsforecast/core.py:467: FutureWarning: The `df` argument of the StatsForecast constructor as well as reusing stored dfs from other methods is deprecated and will raise an error in a future version. Please provide the `df` argument to the corresponding method instead, e.g. fit/forecast.\n",
      "  warnings.warn(\n",
      "/home/user/projects/SAP_AI/env/lib/python3.11/site-packages/statsforecast/core.py:619: FutureWarning: Passing unique_id as the index is deprecated. Please provide it as a column instead.\n",
      "  warnings.warn(\n",
      "/home/user/projects/SAP_AI/env/lib/python3.11/site-packages/statsforecast/core.py:467: FutureWarning: The `df` argument of the StatsForecast constructor as well as reusing stored dfs from other methods is deprecated and will raise an error in a future version. Please provide the `df` argument to the corresponding method instead, e.g. fit/forecast.\n",
      "  warnings.warn(\n",
      "/home/user/projects/SAP_AI/env/lib/python3.11/site-packages/statsforecast/core.py:485: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compute base auto-ARIMA predictions\n",
    "fcst = StatsForecast(df = x_train, models=[AutoARIMA(season_length= 7)], freq='D', n_jobs=-1)\n",
    "x_hat = fcst.forecast(h = horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>6.236943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>6.033696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>6.033696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>6.033696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>6.033696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>1.885268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>1.885268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>1.885268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>1.885268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>1.885268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  AutoARIMA\n",
       "unique_id                      \n",
       "CA        2024-05-16   6.236943\n",
       "CA        2024-05-17   6.033696\n",
       "CA        2024-05-18   6.033696\n",
       "CA        2024-05-19   6.033696\n",
       "CA        2024-05-20   6.033696\n",
       "...              ...        ...\n",
       "WI_3      2024-05-18   1.885268\n",
       "WI_3      2024-05-19   1.885268\n",
       "WI_3      2024-05-20   1.885268\n",
       "WI_3      2024-05-21   1.885268\n",
       "WI_3      2024-05-22   1.885268\n",
       "\n",
       "[98 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>AutoARIMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.847775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.547379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.699377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  y  AutoARIMA\n",
       "unique_id                         \n",
       "CA_1      2024-05-16  2   1.847775\n",
       "CA_2      2024-05-16  0   1.547379\n",
       "CA_3      2024-05-16  1   1.699377"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmat = pd.merge(left = x_test, right = x_hat, on = ['ds', 'unique_id'])\n",
    "xmat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall rmse: 2.2602\n",
      "Country rmse: 4.8227\n",
      "Country/State rmse: 2.8444\n",
      "Country/State/Store rmse: 1.5488\n"
     ]
    }
   ],
   "source": [
    "xmat = pd.merge(left = x_test, right = x_hat, on = ['ds', 'unique_id'])\n",
    "xmat.columns = [['ds', 'y', 'pred']]\n",
    "print('overall rmse: ' + str(my_rmse(xmat['y'], xmat['pred'])))\n",
    "for k in tags.keys():\n",
    "    print(k + ' rmse: ' + str(my_rmse(xmat.loc[tags[k]]['y'], xmat.loc[tags[k]]['pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconcile the base predictions\n",
    "reconcilers = [\n",
    "    BottomUp()\n",
    "]\n",
    "\n",
    "hrec = HierarchicalReconciliation(reconcilers = reconcilers)\n",
    "#x_hat_rec = hrec.reconcile(x_hat, x_train, S, tags)\n",
    "x_hat_rec = hrec.reconcile(x_hat, S, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoARIMA/BottomUp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <th>mse-scaled</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>mse-scaled</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.110586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country/State</th>\n",
       "      <th>mse-scaled</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country/State/Store</th>\n",
       "      <th>mse-scaled</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               AutoARIMA AutoARIMA/BottomUp\n",
       "level               metric                                 \n",
       "Overall             mse-scaled       1.0           0.939187\n",
       "Country             mse-scaled       1.0           1.110586\n",
       "Country/State       mse-scaled       1.0           0.714851\n",
       "Country/State/Store mse-scaled       1.0                1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)\n",
    "\n",
    "evaluator = HierarchicalEvaluation(evaluators=[mse])\n",
    "evaluator.evaluate(Y_hat_df = x_hat_rec, Y_test_df = x_test, \n",
    "                   tags=tags, benchmark='AutoARIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoARIMA/BottomUp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.847775</td>\n",
       "      <td>1.847775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.547379</td>\n",
       "      <td>1.547379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.699377</td>\n",
       "      <td>1.699377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  y  AutoARIMA  AutoARIMA/BottomUp\n",
       "unique_id                                             \n",
       "CA_1      2024-05-16  2   1.847775            1.847775\n",
       "CA_2      2024-05-16  0   1.547379            1.547379\n",
       "CA_3      2024-05-16  1   1.699377            1.699377"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmat = pd.merge(left = x_test, right = x_hat_rec, on = ['ds', 'unique_id'])\n",
    "xmat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall rmse: 2.2602 -> 2.1904\n",
      "Country rmse: 4.8227 -> 5.0823\n",
      "Country/State rmse: 2.8444 -> 2.4049\n",
      "Country/State/Store rmse: 1.5488 -> 1.5488\n"
     ]
    }
   ],
   "source": [
    "xmat = pd.merge(left = x_test, right = x_hat_rec, on = ['ds', 'unique_id'])\n",
    "xmat.columns = [['ds', 'y', 'pred_orig', 'pred_reconciled']]\n",
    "mse1 = my_rmse(xmat['y'], xmat['pred_orig'])\n",
    "mse2 = my_rmse(xmat['y'], xmat['pred_reconciled'])\n",
    "print('overall rmse: ' + str(mse1) + ' -> ' + str(mse2))\n",
    "\n",
    "for k in tags.keys():\n",
    "    mse1 = my_rmse(xmat.loc[tags[k]]['y'], xmat.loc[tags[k]]['pred_orig'])\n",
    "    mse2 = my_rmse(xmat.loc[tags[k]]['y'], xmat.loc[tags[k]]['pred_reconciled'])\n",
    "\n",
    "    print(k + ' rmse: ' + str(mse1) + ' -> ' + str(mse2) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
